{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozLuJF3kIaPF"
   },
   "source": [
    "# Генерация коротких текстов с помощью RNN\n",
    "\n",
    "\n",
    "Генерировать тексты можно с помощью RNN, предсказывающей следующий символ последовательности по предыдущим.\n",
    "\n",
    "В этом задании предлагается написать и проучить на небольшом датасете имен [генеративную модель на основе символов -- Char-RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
    "\n",
    "![charseq](./charseq.jpeg)\n",
    "Картинка взята из [статьи Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_s_Z5lbIaPG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6nXxU8WIaPM"
   },
   "source": [
    "В файле `names` находится ~8k имен на латинице.\n",
    "\n",
    "Модель будет получать на вход имя `Amandy` и выдавать его же, только со сдвигом: `mandy `.\n",
    "\n",
    "Чтобы сеть училась генерировать заглавные буквы, добавим в начало специальный токен, пробел:\n",
    "```\n",
    "_Amandy --> Amandy_\n",
    "```\n",
    "\n",
    "Для практического использования, на каждом шаге будем подавать на вход букву, предсказанную на предыдущем.\n",
    "Так что нам потребуется правило для останова генерации (это может быть просто ограничение на количество шагов).\n",
    "С другой стороны, можно добавить в конец каждого примера обучающей выборки специальный `<EOS>` токен. В данном случае обозначим его `#`:\n",
    "\n",
    "```\n",
    "_Amandy --> Amandy#\n",
    "```\n",
    "\n",
    "Будем прекращать генерацию при досрочном выпадании `<EOS>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFRHva2zIaPN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "eos = '#'\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.readlines()\n",
    "    names = [start_token + name.strip() + eos for name in names]\n",
    "\n",
    "names = list(set(names))  # в датасете есть повторы\n",
    "print('There are {} names: '.format(len(names)))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RizB5cBTIaPP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSve0HBaIaPS"
   },
   "outputs": [],
   "source": [
    "# TODO: постройте частоты употреблений букв\n",
    "<your code>\n",
    "# HINT: для графика возьмите plt.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAeSKss4IaPV"
   },
   "outputs": [],
   "source": [
    "# датасете есть слова с разными длинами\n",
    "MAX_LENGTH = max(map(len,names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len,names)), bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWnDPWr9IaPY"
   },
   "outputs": [],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgB0VE9BIaPa"
   },
   "outputs": [],
   "source": [
    "# TODO: отберите уникальные токены и заполните два словаря для конвертации токенов <-> индексы\n",
    "# сделайте так, чтобы пробел имел номер 0\n",
    "    \n",
    "tokens = <your code>\n",
    "    \n",
    "tok2id = <your code>\n",
    "id2tok = <your code>\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('There are {} tokens',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60\n",
    "\n",
    "print('Vocabular: ' + \"\".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jF_ukJotIaPd"
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=tok2id[' '], dtype=np.int64):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(tok2id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmg_il5MIaPg"
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(names[:10]))\n",
    "print(to_matrix(names[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64C8xOqCIaPk"
   },
   "outputs": [],
   "source": [
    "# TODO: разбейте все имена на тренировочную и тестовую часть\n",
    "<your code>\n",
    "\n",
    "train_data, val_data = split_data(names)\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW62jy6xIaPm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfGnm2QoIaPo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhgqoEHOIaPr"
   },
   "source": [
    "# Char-RNN для имен (0.2 балла)\n",
    "\n",
    "Вам нужно написать сеть, кодирующую номера входных символов с помощью таблицы Embeddings. \n",
    "Получившиеся тензоры пропустить через RNN ячейку, затем преобразовать в логиты для предсказания номера нового символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJCf0LYIIaPt"
   },
   "outputs": [],
   "source": [
    "# NB: обратите внимание на порядок осей при вызове forward\n",
    "# http://pytorch.org/docs/master/nn.html#recurrent-layers\n",
    "\n",
    "# Сделайте возможность выбора типа ячейки, RNN, GRU или LSTM\n",
    "# TODO: заполните пропуски. Функция forward будет вызываться на каждый шаг нами\n",
    "\n",
    "class NameRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size, cell=\"rnn\", n_layers=1):\n",
    "        super(NameRNN, self).__init__()\n",
    "        # добавьте возможность выбрать тип ячейки RNN/LSTM\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.cell = cell\n",
    "        \n",
    "        <your code>\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        <your code>\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.cell == \"lstm\":\n",
    "            return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True),\n",
    "                    torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True))\n",
    "        \n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmkgMHc8IaPu"
   },
   "source": [
    "# Код для тренировки RNN (0.2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S164svO9IaPw"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_batches):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_batches:\n",
    "        # можно вынести подсчет ошибки в модельку\n",
    "        \n",
    "        nums = to_matrix(batch)\n",
    "        <your code>\n",
    "            \n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model, test_batches):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch in test_batches:  \n",
    "        \n",
    "        nums = to_matrix(batch)\n",
    "        <your code>\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)    \n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    \n",
    "    bs = 32\n",
    "    total_steps = 0\n",
    "    train_batches = np.array_split(train_data, len(train_data) // bs)\n",
    "    test_batches = np.array_split(val_data, len(val_data) // bs)\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_epoch(model, opt, train_batches)\n",
    "        train_log.extend(train_loss)\n",
    "        total_steps += len(train_batches)\n",
    "        \n",
    "        val_loss = test(model, test_batches)\n",
    "        train_log.extend(train_loss)\n",
    "        \n",
    "        val_log.append((len(train_log), np.mean(val_loss)))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sxrc0a10IaPy"
   },
   "outputs": [],
   "source": [
    "rnn = NameRNN(len(tokens), 50, len(tokens), cell='rnn')\n",
    "\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=1e-4)\n",
    "train(rnn, opt, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8wvbm8HIaP1"
   },
   "outputs": [],
   "source": [
    "rnn = NameRNN(len(tokens), 50, len(tokens), cell='lstm')\n",
    "\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=1e-4)\n",
    "train(rnn, opt, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ffTAktWAIaP5"
   },
   "source": [
    "# Генерация по argmax (0.2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugRlkX2ZIaP6"
   },
   "outputs": [],
   "source": [
    "# Напишите функцию генерации продолжения строки\n",
    "def pick_by_argmax(logits):\n",
    "    <your code>\n",
    "\n",
    "def ids2string(ids):\n",
    "    return \"\".join(id2tok[_] for _ in ids)\n",
    "\n",
    "\n",
    "def gen_continuation(model, prefix=\" \"):\n",
    "    hidden = model.init_hidden(1)\n",
    "    nums = to_matrix(prefix)\n",
    "    nums = torch.from_numpy(nums)\n",
    "    \n",
    "    # TODO: сначала сверните строку с помощью RNN:\n",
    "    # нас интересует последний output и hidden\n",
    "    <your code>\n",
    "    \n",
    "    # TODO: затем сгенерируйте несколько последующих символов\n",
    "    # outs -- это массив с номерами токенов\n",
    "    <your code>\n",
    "    \n",
    "    print(prefix + '|'+ ids2string(outs))\n",
    "    \n",
    "gen_continuation(rnn, \" Ku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00547AA-IaP_"
   },
   "source": [
    "# Генерация с семплированием (0.4 балла)\n",
    "\n",
    "Обычный софтмакс \n",
    "$$p_i = \\frac{\\exp (x_i)}{\\sum \\exp (x_j)}$$\n",
    "можно модернизировать с помощью температуры:\n",
    "$$p_i = \\frac{\\exp (x_i / T)}{\\sum \\exp (x_j / T)}$$\n",
    "\n",
    "Это позволит плавно переходить от выбора наиболее вероятного элемента ($T << 1$) до практически равновероятного ($T >> 1$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71cOcFxpIaQA"
   },
   "outputs": [],
   "source": [
    "# Напишите функцию генерации батчами с семплированием из распределения и температурой\n",
    "def batch2string(ids, prefix):\n",
    "    # модифицируйте ids2string для работы с батчами\n",
    "    <your code>\n",
    "\n",
    "def pick_by_distribution(logits):\n",
    "    # превратите логиты в распределение\n",
    "    # затем семлируйте из него batch примеров\n",
    "    <your code>\n",
    "\n",
    "\n",
    "def gen_continuation_temp(model, prefix=\" \", temperature=1.0, n=10):\n",
    "    hidden = model.init_hidden(n)\n",
    "    nums = to_matrix([prefix] * n)\n",
    "    nums = torch.from_numpy(nums)\n",
    "\n",
    "    # аналогично, сначала получите батч output, hidden\n",
    "    <your code>\n",
    "    \n",
    "    # затем, сгенерируйте n последующих символов\n",
    "    # в outs положите матрицу номеров токенов и отобразите ее\n",
    "    \n",
    "    print(batch2string(outs, prefix + '|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pElLbEKIaQD"
   },
   "outputs": [],
   "source": [
    "gen_continuation_temp(rnn, prefix=\" An\", temperature=0.5, n=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL18_seminar6.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
